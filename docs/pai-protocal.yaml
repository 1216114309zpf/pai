
protocol_version: String, optional # Protocol version. Default is v2
name: String, required
type: String, required # The type of the component. Must be one of the following: job, data, script, dockerimage, or output
version: String, optional # Component version. Default is latest
contributor: String, optional
description: String, optional

prerequisites:
  - protocol_version: String, optional # Protocol version. Default is v2
    name: String, required
    type: String, required # Component type. Must be one of the following: data, script, dockerimage, or output. Prerequisites.type cannot be "job"
    version: String, optional # Component version. Default is latest
    contributor: String, optional
    description: String, optional
    auth: Object, optional # Only available when the type is dockerimage
      username: String, optional
      passward: String, optional
      registryuri: String, optional
    uri: String or list, required # Only when the type is data can the uri be a list

parameters: # Optional, can be omitted
  <param1>: value1Type # Specify name and value of all the referencable parameters that will be used in the whole job template. They can be referenced by $$paramName$$.
  <param2>: value2Type

taskRoles:
  - protocol_version: String, optional # Protocol version, default is v2
    name: String, required  # Name of the taskRole
    dockerimage: String, required # Should reference to a dockerimage defined in prerequisites.
    data: Object, optional # Default is None
    output: Object, optional # Default is None
    script: Object, optional # Default is None
    resource:
      instances: Integer, optional # Default is 1
      resourcePerInstance:
        cpu: Integer, required
        memoryMB: Integer, required
        shmMB: Integer, optional # Default is 64
        gpu: Integer, required
      ports:
        <portLabel1>: Integer, optional, default is 0 # Only for host network
    completion:
      minFailedInstances: Integer, optional # Default 1
      minSucceededInstances: Integer or null, optional # Default null
    command:
      - String, required

deployment_specific:
  - protocol_version: String, optional # Protocol version, default is v2
    name: String, required
    jobRetryCount: Integer, optional # Default is 0
    virtualCluster: String # Default is "default"
    taskRoles:
      - name: String, required # Should be the same as taskRoles.name
        preCommands:
          - String, required # execute before $$taskRoles.name.command$$
        postCommands:
          - String, required # execute after $$taskRoles.name.command$$

# Below is an example for distributed tensorflow:

protocol_version: v2
name: tensorflow_cifar10
type: job
version: 1.0.0
contributor: Alice
description: image classification, cifar10 dataset, tensorflow, distributed training

prerequisites:
  - protocol_version: v2
    name: tf_example
    type: dockerimage
    version: latest
    contributor: Alice
    description: python3.5, tensorflow
    auth:
      username: 81f1fd6a-2844-4072-982d-62371fa37bd3
      passward: user1
      registryuri: openpai.azurecr.io
    uri: openpai/pai.example.tensorflow
  - protocol_version: v2
    name: tensorflow_cifar10_model
    type: output
    version: latest
    contributor: Alice
    description: cifar10 data output
    uri: hdfs://10.151.40.179:9000/core/cifar10_model
  - protocol_version: v2
    name: tensorflow_cnnbenchmarks
    type: script
    version: 84820935288cab696c9c2ac409cbd46a1f24723d
    contributor: MaggieQi
    description: tensorflow benchmarks
    uri: https://github.com/MaggieQi/benchmarks
  - protocol_version: v2
    name: cifar10
    type: data
    version: latest
    contributor: Alice
    description: cifar10 dataset, image classification
    uri:
      - https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

parameters:
  model: resnet20
  batchsize: 32

taskRoles:
  - protocol_version: v2
    name: worker
    dockerimage: tf_example
    data: { cifar10: prerequisites.[data,cifar10] }
    output: { tf_cifar10_model: prerequisites.[output,tensorflow_cifar10_model] }
    script: { tf_cnnbenchmarks: prerequisites.[script,tensorflow_cnnbenchmarks] }
    resource:
      instances: 1
      resourcePerInstance: { cpu: 2, memoryMB: 16384, shmMB: 64, gpu: 4 }
      ports: { ssh: 0, http: 0 } # only host network support
    completion:
      minFailedInstances: 0
      minSucceededInstances: 1
    command:
      - cd script_$$taskRoles.worker.script.tf_cnnbenchmarks.name$$/scripts/tf_cnn_benchmarks
      - >- python tf_cnn_benchmarks.py --job_name=worker --local_parameter_device=gpu --variable_update=parameter_server
      --ps_hosts=$PAI_TASK_ROLE_ps_server_HOST_LIST --worker_hosts=$PAI_TASK_ROLE_worker_HOST_LIST --task_index=$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX
      --data_dir=$PAI_WORK_DIR/data_$$taskRoles.worker.data.cifar10.name$$ --data_name=$$taskRoles.worker.data.cifar10.name$$
      --train_dir=$PAI_WORK_DIR/output_$$taskRoles.worker.output.tf_cifar10_model.name$$
      --model=$$parameters.model$$ --batch_size=$$parameters.batchsize$$

  - protocol_version: v2
    name: ps_server
    dockerimage: tf_example
    data: { cifar10: prerequisites.[data,cifar10] }
    output: { tf_cifar10_model: prerequisites.[output,tensorflow_cifar10_model] }
    script: { tf_cnnbenchmarks: prerequisites.[script,tensorflow_cnnbenchmarks] }
    resource:
      instances: 1
      resourcePerInstance: { cpu: 2, memoryMB: 8192, shmMB: 64, gpu: 0 }
    completion:
      minFailedInstances: 0
      minSucceededInstances: 1
    command:
      - cd script_$$taskRoles.ps_server.script.tf_cnnbenchmarks.name$$/scripts/tf_cnn_benchmarks
      - >- python tf_cnn_benchmarks.py --job_name=ps --local_parameter_device=gpu --variable_update=parameter_server
      --ps_hosts=$PAI_TASK_ROLE_ps_server_HOST_LIST --worker_hosts=$PAI_TASK_ROLE_worker_HOST_LIST --task_index=$PAI_CURRENT_TASK_ROLE_CURRENT_TASK_INDEX
      --data_dir=$PAI_WORK_DIR/data_$$taskRoles.ps_server.data.cifar10.name$$ --data_name=$$taskRoles.ps_server.data.cifar10.name$$
      --train_dir=$PAI_WORK_DIR/output_$$taskRoles.ps_server.output.tf_cifar10_model.name$$
      --model=$$parameters.model$$ --batch_size=$$parameters.batchsize$$

deployment_specific:
  - protocol_version: v2
    name: no_data_cache_local_output_and_hdfs # This implementation assumes no local data cache, model output to local disk and being copied to hdfs
    version: 1.0.0
    jobRetryCount: 0
    virtualCluster: default
    taskRoles:
      - name: worker
        preCommands:
          - wget $$taskRoles.worker.data.cifar10.uri$$ -P data_$$taskRoles.worker.data.cifar10.name$$ # if local data cache deployed, one can copy data from local cache, only wget in case of cache miss
          - > git clone $tasks.worker.script.tensorflow_cnnbenchmarks.uri$$ script_$$tasks.worker.script.tf_cnnbenchmarks.name$$ &&
            cd script_$$taskRoles.worker.script.tf_cnnbenchmarks.name$$ && git checkout $$taskRoles.worker.script.tf_cnnbenchmarks.version$$ && cd ..
          # and the system will go ahead to execute $$taskRoles.ps_server.command$$
      - name: ps_server
        preCommands:
          - wget $$taskRoles.ps_server.data.cifar10.uri$$ -P data_$$taskRoles.ps_server.data.cifar10.name$$
          - > git clone $tasks.ps_server.script.tensorflow_cnnbenchmarks.uri$$ script_$$tasks.ps_server.script.tf_cnnbenchmarks.name$$ &&
          cd script_$$taskRoles.ps_server.script.tf_cnnbenchmarks.name$$ && git checkout $$taskRoles.ps_server.script.tf_cnnbenchmarks.version$$ && cd ..
          # and the system will go ahead to execute $$taskRoles.ps_server.command$$
        postCommands:
          # after the execution of $$taskRoles.ps_server.command$$, the system goes here
          - hdfs dfs -cp output_$$taskRoles.ps_server.output.tf_cifar10_model.name$$ $$taskRoles.ps_server.output.tf_cifar10_model.uri$$
          # assume the model is output locally, and this command copies the local output to hdfs. One can output to hdfs directly. In this case, you will have to change "--train_dir=$PAI_WORK_DIR/output_$$taskRoles.ps_server.output.tf_cifar10_model.name$$"

